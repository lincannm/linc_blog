[{"title":"在已存在Windows的电脑（VMware环境）上安装Arch Linux（双系统）与KDE桌面环境","path":"/article/ad5e93bb.html","content":"想要装Windows + Arch Linux双系统，然而BIOS密码忘记了。。。。搞得我不能关安全启动（Secure Boot）安装双系统了。。。不过，即使是开了安全启动，一般来说也是有办法的嘛。。但是我试图用了支持安全启动的Ubuntu和Fedora， 傻逼联想BIOS 死活不能加载。为了记录好不容易学会的安装方法，只能在VMware上的一个已经装好Windows 11的虚拟机上操作一番，并于本文记录安装过程，万一以后想起密码了呢。。 官方安装指南，多读多看：安装指南 - Arch Linux 中文维基 本文采取手动安装的方式，而不是archinstall的方式。 Arch Linux 安装提前分区，并启动LiveCD进入pe系统，在分区软件中给linux预留出足够的空间出来，成为一段未分配空间。记得给EFI分区分配至少200MB的空间，否则到后面GRUB引导会因为空间不足安装失败（安装后实占空间110MB）。 插上LiveCD，启动的时候从CD（实体机为USB设备）启动。 看见这个界面，就能开始安装。 在完成安装之前，一切操作都在这里进行。 验证引导模式1cat /sys/firmware/efi/fw_platform_size # UEFI_x64 == 64 配置网络VMware中不能配置wifi网络，只能以有线网络进行配置，而且默认已经能连上网络了，无需配置。因此，配置wifi网络的部分此处只能省略。 配置系统时间timedatectl(1) — Arch manual pages 12timedatectl # 可查看当前系统时间timedatectl set-timezone Asia/Shanghai # 配置时区为上海 硬盘分区创建分区使用cfdisk进行硬盘分区，方便一点。 cfdisk - Arch Linux 中文维基 12fdisk -l # 查看当前硬盘设备及分区cfdisk /dev/nvme0n1 # 对/dev/nvme0n1这个硬盘进行分区 EFI分区已存在，只要创建个swap分区和根目录分区即可。 格式化分区12mkfs.ext4 /dev/&lt;根分区&gt;mkswap /dev/&lt;swap分区&gt; 挂载分区 根据官方文档，挂载分区一定要遵循顺序，先挂载根（root）分区（到 /mnt），再挂载引导（boot）分区（到 /mnt/boot ），最后再挂载其他分区。否则可能遇到安装完成后无法启动系统的问题。 123mount /dev/&lt;根分区&gt; /mnt # 先把根分区挂载到/mntmount --mkdir /dev/&lt;EFI分区&gt; /mnt/boot # 再把EFI分区挂载到/mnt/bootswapon /dev/&lt;swap分区&gt; # 启用swap分区 安装系统安装基本系统1234vim /etc/pacman.d/mirrorlist # 编辑源为国内镜像源pacman -Sy archlinux-keyring # 更新keyringpacstrap -K /mnt base linux linux-firmware vim networkmanager # 向硬盘安装base软件包、linux内核、linux固件 与 vim、网络管理器genfstab -U /mnt &gt; /mnt/etc/fstab # 向已安装的新系统生成fstab linux-firmware在虚拟机可以不用安装。vim和networkmanager是附加的，方便后续编辑文本和配置网络。 生成的fstab文件用于定义在系统启动时自动挂载的文件系统。 配置系统123arch-chroot /mnt # chroot到新安装的系统ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime # 设置时区hwclock --systohc # 生成 /etc/adjtime 本地化设置编辑 /etc/locale.gen 1vim /etc/locale.gen 然后取消掉 en_US.UTF-8 UTF-8的注释，接着执行： 1locale-gen 编辑/etc/locale.conf 1vim /etc/locale.conf 然后设置LANG变量： 1LANG=en_US.UTF-8 编辑/etc/hostname： 1vim /etc/hostname 之后写入主机名。 设置root密码1passwd 安装GRUB引导没有grub，就引导不了我们的archlinux。 1pacman -Sy grub efibootmgr os-prober # os-prober用来探测别的操作系统 为了使用os-proper来探测我们的Windows系统，编辑/etc/default/grub并取消下面这一行的注释： 1GRUB_DISABLE_OS_PROBER=false 安装GRUB： 12grub-install --target=x86_64-efi --efi-directory=/boot # 把grub安装到efi分区grub-mkconfig -o /boot/grub/grub.cfg # 生成grub.cfg配置文件 整个ArchLinux到此安装完毕。 输入exit退出chroot环境，输入reboot启动！ 安装后基本配置配置网络由于是在虚拟机下安装的，此处按照有线网络来配置。 1ip link #查看网络设备 1ip link set dev ens160 up # 启动设备ens160 网络管理器有以下几种： 使用NetworkManager这个网络管理器配置网络，毕竟有nmtui这个工具方便点。 12systemctl enable --now NetworkManager # 设置NetworkManager开机自启并立即启动nmtui # 启动命令行UI 选中ens33按enter取消连接（自动消失可还行），下面的有线连接1自动激活。 这样确保它启用了（前面有个星号，右边按钮是Deactivate按钮），然后就可以连接互联网了。可以ping baidu.com试试看。 其实主要还是因为一开始没有DHCP自动获取ip，而NetworkManager刚好内置这个服务，获取ip成功后就能上网了。只安装dhcpcd这个DHCP服务其实也是一样的效果，也能上网。 新建用户123pacman -Sy sudo # 安装sudo，这玩意不自带useradd -m -G wheel linc # 创建用户，名字为linc，创建用户主目录，且用户属于wheel用户组（可以用sudo）passwd linc # 设置密码 编辑/etc/sudoers文件，取消这行注释，以启用wheel用户组： 安装SSH12pacman -Sy opensshsystemctl enable --now sshd 编辑/stc/ssh/sshd_config，添加PermitRootLogin yes（取消注释并修改），以允许通过ssh登录root用户。 使用systemctl restart sshd让配置生效 安装zsh1pacman -Sy zsh zsh-completions 编辑~/.zshrc，简单配置如下（参考的是ArchWiki的配置）： 123456autoload -Uz compinit promptinitcompinitpromptinit# 将默认命令行提示设置为 walters 主题prompt walters 执行source ~/.zshrc生效。 安装KDE12pacman -Sy plasma kde-applications # 安装plasma6和其配套软件systemctl enable --now sddm # 设置sddm自启动并启动sddm显示管理器 VMware需要安装open-vm-tools（参考：VMware&#x2F;安装 Arch Linux 为虚拟机 - Arch Linux 中文维基）： 1234sudo pacman -Sy open-vm-tools# 安装完要开启两个服务：vmtoolsd 和 vmware-vmblock-fusesystemctl enable --now vmtoolsdsystemctl enable --now vmware-vmblock-fuse 中文化 去kde的设置，切换语言为中文简体，之后会提示重启系统，字体还没装先不重启。 安装思源黑体，不然显示不了中文： 1sudo pacman -Sy adobe-source-han-sans-cn-fonts 重启系统就好了。 解决问题（在VMware下）声音极其卡顿在我的虚拟机上，声音卡的一笔。。尝试了几个解决办法，把自带的pipewire换成pulseaudio可以解决。然而直接安装pulseaudio会提示与pipewire冲突： 123456789[linc@VM ~]$ sudo pacman -Sy pulseaudio:: Synchronizing package databases... core is up to date extra extra is up to date resolving dependencies...looking for conflicting packages...:: pulseaudio-17.0+r43+g3e2bb8a1e-1 and pipewire-pulse-1:1.2.7-1 are in conflict. Remove pipewire-pulse? [y/N] yerror: failed to prepare transaction (could not satisfy dependencies):: removing pipewire-pulse breaks dependency &#x27;pipewire-pulse&#x27; required by pulse-native-provider 所以需要卸载pipewire： 1sudo pacman -Rdd pipewire-pulse 安装pulseaudio（和pulseaudio-alsa）： 1sudo pacman -Sy pulseaudio pulseaudio-alsa 重启，ok。 然而过一段时间声音又发不出来了。。因此需要禁用 PulseAudio 的自动挂起功能： 编辑 PulseAudio 的配置文件/etc/pulse/default.pa，找到这一行： 1load-module module-suspend-on-idle 用#注释掉，重启就行。","tags":["Linux","Arch Linux","双系统","KDE","笔记"],"categories":["Linux","笔记"]},{"title":"如何在WSL的Ubuntu 24.04上通过VcXsrv使用Xfce桌面","path":"/article/b54c182.html","content":"感觉在VMware上用Ubuntu的图形界面太卡了，所以就用上WSL（介绍：什么是适用于 Linux 的 Windows 子系统 | Microsoft Learn）了。通过xrdp连接Gnome和KDE桌面都挺卡，使用X11协议（通过VcXsrv）则不会有太大卡顿。然而可惜KDE在VcXsrv上会有显示问题，怎么也未能解决，只能用Xfce桌面了。网上现有的资料都是用VcXsrv显示Xfce桌面，也不知道为什么不提提别的桌面，别的桌面（如KDE）有问题也稍微提一嘴啊。。 安装WSL，安装Ubuntu 24.04此处不多说，自行看官方文档。 安装 WSL | Microsoft Learn 网络模式设置为Mirrored打开WSL Settings，来到网络页面，网络模式改成Mirrored（桥接），否则不能跟VcXsrv建立连接。改完别忘了wsl --shutdown。 VcXsrv电脑上可以用Xming或VcXsrv来通过X11协议使用桌面，不过Xming就坑爹了，2025年更新的最新版本却需要捐助才能下载，免费下载的版本竟停留在2007年。07年的版本实测会卡死，还是用免费开源的VcXsrv吧！听说WSL微软推荐使用VcXsrv，但我暂时没有在官方文档看见这样的描述。 安装在这里下载：Releases · marchaesen&#x2F;vcxsrv 安装完后不知为何不会显示在开始菜单上的应用程序列表上，只会在桌面建立一个快捷方式。点击这个快捷方式启动就好。 启动 选择One large window 默认 勾选Disable access control 完成 Xfce1. 安装1sudo apt install -y xfce4 xorg # 安装Xfce和xorg 2. 设置DISPLAY环境变量（关键）1sudo vim .bashrc 在最后一行写上： 1export DISPLAY=localhost:0 使.bashrc生效： 1source ~/.bashrc 这样就行。有资料说要依照/etc/resolf.conf的nameserver的ip进行设置，试了一下无效。我又设置成:0.0，VcXsrv不会显示画面。搞了不知道多久了，自己试了下localhost，竟然ok了。。。 3. 启动Xfce执行： 1sudo startxfce4 回到VcXsrv，xfce就有了！ 可以执行sudo startxfce4 &amp;让他后台执行。 问题如果用KDE桌面并用startplasma-x11启动的话，看起来会变这样（已经进入桌面）： 窗口会被这一坨黑挡住。什么破玩意。。 只能用Xfce了，然而以前在Termux早把Xfce玩惯了。还是回到VMware吧！ （Gnome桌面并没有测试，因为懒）","tags":["Linux","WSL","Ubuntu","Xfce"],"categories":["Linux"]},{"title":"解决Hexo+Typora引用图片不方便问题","path":"/article/f83728a5.html","content":"参考：hexo+typora+github图片路径问题 - 简书 参照 资源文件夹 | Hexo 对_config.yml进行如下设置： 1234post_asset_folder: truemarked: prependRoot: true postAsset: true Typora进行如下设置： 然而在typora粘贴图片后，typora可以渲染，hexo由于路径问题，渲染失败。 在typora中，图片路径为测试文章/001.png；而在hexo的网页上，图片路径被渲染为http://localhost:4000/测试文章/001.png。而只有在typora中把图片路径写作001.png，才能在网页中被正确渲染为http://localhost:4000/2025/02/06/测试文章/001.png。但这样的话，typora不就因为文件路径不存在而无法显示图片了吗？ 查了点资料，只能手动修改hexo-render-marked模块的renderer.js了。在以下位置添加代码： 123if(href.indexOf(&quot;/&quot;)&gt;0)&#123;\thref=href.split(&#x27;/&#x27;)[1];&#125; 问题解决。。。","tags":["Hexo","Typora"],"categories":["Hexo"]},{"title":"在780M核显笔记本上通过LM Studio本地化部署DeepSeek大模型","path":"/article/c73044ca.html","content":"本来想用Ollama部署LLM，但我下载启动Ollama后发现官方不支持我的Radeon 780M核显（gfx1103）： 123456789101112C:\\Users\\lincannm&gt;ollama serve2025/02/01 18:01:29 routes.go:1187: INFO server config env=&quot;map[CUDA_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:C:\\\\Users\\\\lincannm\\\\.ollama\\\\models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:0 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://*] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES:]&quot;time=2025-02-01T18:01:29.821+08:00 level=INFO source=images.go:432 msg=&quot;total blobs: 0&quot;time=2025-02-01T18:01:29.822+08:00 level=INFO source=images.go:439 msg=&quot;total unused blobs removed: 0&quot;time=2025-02-01T18:01:29.823+08:00 level=INFO source=routes.go:1238 msg=&quot;Listening on 127.0.0.1:11434 (version 0.5.7)&quot;time=2025-02-01T18:01:29.825+08:00 level=INFO source=routes.go:1267 msg=&quot;Dynamic LLM libraries&quot; runners=&quot;[cuda_v12_avx rocm_avx cpu cpu_avx cpu_avx2 cuda_v11_avx]&quot;time=2025-02-01T18:01:29.825+08:00 level=INFO source=gpu.go:226 msg=&quot;looking for compatible GPUs&quot;time=2025-02-01T18:01:29.825+08:00 level=INFO source=gpu_windows.go:167 msg=packages count=1time=2025-02-01T18:01:29.825+08:00 level=INFO source=gpu_windows.go:214 msg=&quot;&quot; package=0 cores=8 efficiency=0 threads=16time=2025-02-01T18:01:30.397+08:00 level=WARN source=amd_windows.go:140 msg=&quot;amdgpu is not supported (supported types:[gfx1030 gfx1100 gfx1101 gfx1102 gfx906])&quot; gpu_type=gfx1103 gpu=0 library=C:\\Users\\lincannm\\AppData\\Local\\Programs\\Ollama\\lib\\ollamatime=2025-02-01T18:01:30.400+08:00 level=INFO source=gpu.go:392 msg=&quot;no compatible GPUs were discovered&quot;time=2025-02-01T18:01:30.400+08:00 level=INFO source=types.go:131 msg=&quot;inference compute&quot; id=0 library=cpu variant=avx2 compute=&quot;&quot; driver=0.0 name=&quot;&quot; total=&quot;27.8 GiB&quot; available=&quot;20.3 GiB&quot; 听说还有个叫做LM Studio的东西，对我这样的780M核显支持不错，可以直接用。而且Ollama是命令行使用，而LM Studio则是GUI操作，更加人性化。 下载与安装LM Studio官网：https://lmstudio.ai/ 下载它： 安装就不必多说了吧。 使用点开侧边栏第四个图标，弹出此“发现”窗口。首先到这里看看，由于我的GPU是AMD Radeon 780M，在这里看看确保选中了Vulkan选项，这样运行LLM的时候才会调用到显卡。 App Settings可以设置界面为中文。 到“Model Search”下载DeekSeek模型。由于我的显存只有可怜的4G，我就下载大小为4G左右的7B版本就好。 下载完成！回到聊天界面，到顶栏选择模型。 根据电脑配置配置这些配置~（GPU Offload被译为GPU卸载有点别扭，网上查了一下，其实就是根据当前GPU的显存性能来调节线条，值越高，就意味着运行模型的性能占比交给GPU的更高） 点一下加载模型就加载好了。部署到此结束，整个过程都非常简单。 开始聊天，思考过程中笔记本风扇直接起飞。 回复太人机了，完整版DeepSeek会跟我解析这段话的幽默性。这样也很正常，完整版671B，我才7B的模型根本比不了。 网络优化我是翻墙出去下载的模型，如果没有翻墙条件的话可以打开LM Studio安装目录，用vscode把目录下所有文件做全局替换——把所有huggingface.co替换为hf-mirror.com即可。 问题不知道为什么我的核显占用很小，几乎闲着，而且一把GPU Offload调大就报Unknown error。。。全网找不到解决办法。 后来我下载了14B的模型，终于懂得解析幽默性了，这下就聪明多了。但是我让它用贴吧语气锐评ChatGPT，依旧不聪明，甚至都不知道是在骂ChatGPT还是在骂我。。。 问题解决核显占用小的问题解决了！搞了两天原来更新一下amd显卡驱动就好了。。。更新了之后，GPU Offload可以全部拉满，可以全部交给显卡计算了。 Ollama-for-amd在那个问题解决之前，试了一下Ollama-for-amd项目（https://github.com/likelovewant/ollama-for-amd/），该项目针对amd显卡进行支持性扩展，通过这个项目我的780M也能跑ollama了。安装的话直接下载Release里面的exe就行了。 然而聊天会有bug，不仅没有深度思考过程，后面我每说一句它还只会直接接我的话。不过既然问题解决了，干脆接着用LMStudio算了吧。","tags":["LLM"],"categories":["摸鱼"]},{"title":"创建了一个基于Hexo和Vercel的博客！","path":"/article/b8b788b0.html","content":"春节快乐🎉🎉！突发奇想想搞个博客网站，于是就花了15块钱（首年）买下 linc.work 这个域名，通过 Hexo + Redefine主题 + Github + Vercel 搭建了这个网站（另外通过 LeanCloud + Vercel 搞了文章下的 Waline 评论系统）。 搞个博客网站主要是可以分享点东西，记录点东西，当然直接原因还是春节无聊搞着玩的。有群友叫我玩玩Hugo，但是我玩过，不会玩，还是Hexo在网上的资料多一点，适合小白操作。博客这玩意不少搞计算机的都有，我不搞显得我不专业（ 博客折腾了两天才搞好。我在我电脑上用VMware装了个Ubuntu 24.04.1，安装nodejs，然后搭建hexo环境，安装Redefine主题，之后用 hexo deploy 把博客的静态页面部署到GitHub上，再通过Vercel把GitHub仓库部署到Vercel上面，最后再把域名解析到Vercel上边就好了。 几乎三年没玩技术了，直到最近才听说Vercel挺好用，用了一下还真是个好东西。除了部署静态页面，后端也都能部署（比GitHub Pages牛），而且还能免费使用（白嫖），确实牛逼。 （头图pid：115320144）","tags":["第一篇文章"],"categories":["摸鱼"]},{"path":"/baidu_verify_codeva-5ghC7sLlrI.html","content":"0181ffad9103fbf1e4cf453849d7d15f"},{"title":"关于","path":"/about/index.html","content":"自述现读大一，经过高中三年摸鱼，目前啥也不精（悲），只是了解点Web开发（技术栈为 HTML&#x2F;CSS&#x2F;JS&#x2F;PHP，然而没想到现在Web技术花样越来越多，NodeJS、Vue、React、EJS、SASS、Stylus这的那的，tm真跟不上时代了）和Java而已，刚学会学校教的 C 语言。我还会点版式设计，以前寻思要给班里和动漫社搞海报学的，水平不高。 2025 年过年的时候闲着没事干就搞了这个网站。 Lincannm 是我不知道四年级还是五年级的时候设置的网名，源自注册百度账号的时候，本来想定为 Lincan （姓名前两字拼音），发现名字被占用，于是加了个n，发现名字依旧被占用，一气之下再加了个m，注册成功…… 本博客的头像是从我的GitHub加载过来的，是初中时候的QQ头像。QQ早就换头像了（本站浏览器标签上的小缩略图），但GitHub上一直没换，现在也懒得换了。"}]